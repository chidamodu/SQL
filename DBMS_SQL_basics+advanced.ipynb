{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Properties of RDBMS?\n",
    "\n",
    "Features:\n",
    "\n",
    "- Provides data to be stored in tables\n",
    "\n",
    "- Persists data in the form of rows and columns\n",
    "\n",
    "- Provides facility primary key, to uniquely identify the rows\n",
    "\n",
    "- Creates indexes for quicker data retrieval\n",
    "\n",
    "- Provides a virtual table creation in which sensitive data can be stored and simplified query can be applied.(views)\n",
    "\n",
    "- Sharing a common column in two or more tables(primary key and foreign key)\n",
    "\n",
    "- Provides multi user accessibility that can be controlled by individual users.\n",
    "\n",
    "\n",
    "The most common use of RDBMS is to implement simple CRUD – Create, Read, Update, and Delete – functionality.\n",
    "\n",
    "For example an application could create a new order and insert it into your database. It could read an existing order, work with the data, and then update the database with the new information. It could also choose to delete an existing order, perhaps because the customer has cancelled it.\n",
    "\n",
    "The vast majority of your interaction with an RDB will likely be to implement basic CRUD functionality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Write a SQL query to retrieve furniture from database whose dimensions(Width, Height, Length) match with the given dimension.\n",
    "Ans.\n",
    "\n",
    "SELECT *\n",
    "FROM Furnitures\n",
    "WHERE Furnitures.Length = GivenLength\n",
    "  AND Furnitures.Breadth = GivenBreadth\n",
    "  AND Furnitures.Height = GivenHeight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Print the second largest number in the table.\n",
    "assign a variable and calculate row count. Pull out the count=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Explain 3 tier architecture and 2 tier architectures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Write a SQL query to find the 4th maximum element from a table\n",
    "One of the ways is to calculate rank and pull out rank=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Difference between INNER and OUTER JOIN.\n",
    "\n",
    "Inner join - An inner join using either of the equivalent queries gives the intersection of the two tables, i.e. \n",
    "the two rows they have in common.\n",
    "\n",
    "Left outer join - A left outer join will give all rows in A, plus any common rows in B.\n",
    "\n",
    "Full outer join - A full outer join will give you the union of A and B, i.e. All the rows in A and all the rows in B. \n",
    "If something in A does not have a corresponding datum in B, then the B portion is null, and vice versa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Types of JOIN in DBMS.\n",
    "\n",
    "Here are the different types of the JOINs in SQL:\n",
    "\n",
    "(INNER) JOIN: Returns records that have matching values in both tables\n",
    "LEFT (OUTER) JOIN: Returns all records from the left table, and the matched records from the right table\n",
    "RIGHT (OUTER) JOIN: Returns all records from the right table, and the matched records from the left table\n",
    "FULL (OUTER) JOIN: Returns all records when there is a match in either left or right table\n",
    "    \n",
    "    \n",
    "Natural Join = the join (the ON clause) is made on all columns with the same name; it removes duplicate columns from\n",
    "the result, as opposed to all other joins; most DBMS (database systems created by various vendors such as Microsoft\n",
    "SQL Server, Oracle's MySQL etc. ) don't even bother supporting this, it is just bad practice\n",
    "(or purposely chose not to implement it). Imagine that a developer comes and changes the name of the second column in\n",
    "Product from Price to Cost. Then all the natural joins would be done on PName AND on Cost, resulting in 0 rows since\n",
    "no numbers match.\n",
    "\n",
    "Theta Join = this is the general join everybody uses because it allows you to specify the condition\n",
    "(the ON clause in SQL). You can join on pretty much any condition you like, for example on Products that have the\n",
    "first 2 letters similar, or that have a different price. In practice, this is rarely the case - in 95% of the cases \n",
    "you will join on an equality condition, which leads us to:\n",
    "\n",
    "Equi Join = the most common one used in practice. The example above is an equi join. Databases are optimized for this\n",
    "type of joins! The oposite of an equi join is a non-equi join, i.e. when you join on a condition other than \"=\".\n",
    "Databases are not optimized for this! Both of them are subsets of the general theta join.\n",
    "The natural join is also a theta join but the condition (the theta) is implicit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACID properties\n",
    "\n",
    "ACID (Atomicity, Consistency, Isolation, Durability) is the historical justification for using a database.\n",
    "\n",
    "Atomicity\n",
    "All changes to data are performed as if they are a single operation. That is, all the changes are performed, or none \n",
    "of them are.\n",
    "For example, in an application that transfers funds from one account to another, the atomicity property ensures that, \n",
    "if a debit is made successfully from one account, the corresponding credit is made to the other account.\n",
    "\n",
    "\n",
    "Consistency\n",
    "Data is in a consistent state when a transaction starts and when it ends.\n",
    "For example, in an application that transfers funds from one account to another, the consistency property ensures that\n",
    "the total value of funds in both the accounts is the same at the start and end of each transaction.\n",
    "\n",
    "\n",
    "Isolation\n",
    "The intermediate state of a transaction is invisible to other transactions. As a result, transactions that run \n",
    "concurrently appear to be serialized.\n",
    "For example, in an application that transfers funds from one account to another, the isolation property ensures that \n",
    "another transaction sees the transferred funds in one account or the other, but not in both, nor in neither.\n",
    "\n",
    "\n",
    "Durability\n",
    "After a transaction successfully completes, changes to data persist and are not undone, even in the event of a system \n",
    "failure.\n",
    "For example, in an application that transfers funds from one account to another, the durability property ensures that \n",
    "the changes made to each account will not be reversed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Keys in DBMS.\n",
    "\n",
    "Seven Types of DBMS keys are Super, Primary, Candidate, Alternate, Foreign, Compound, Composite, and Surrogate Key. \n",
    "\n",
    "Candidate Key - The candidate keys in a table are defined as the set of keys that is minimal and can uniquely \n",
    "identify any data row in the table.\n",
    "\n",
    "The different types of keys in DBMS are:\n",
    "\n",
    "Candidate Key - The candidate keys in a table are defined as the set of keys that is minimal and can uniquely identify\n",
    "any data row in the table.\n",
    "\n",
    "Primary Key - The primary key is selected from one of the candidate keys and becomes the identifying key of a table.\n",
    "It can uniquely identify any data row of the table.\n",
    "\n",
    "Super Key - Super Key is the superset of primary key. The super key contains a set of attributes, including the \n",
    "primary key, which can uniquely identify any data row in the table.\n",
    "\n",
    "Composite Key - If any single attribute of a table is not capable of being the key i.e it cannot identify a row \n",
    "uniquely, then we combine two or more attributes to form a key. This is known as a composite key.\n",
    "\n",
    "Secondary Key - Only one of the candidate keys is selected as the primary key. The rest of them are known as secondary\n",
    "keys.\n",
    "\n",
    "Foreign Key - A foreign key is an attribute value in a table that acts as the primary key in another another. Hence,\n",
    "the foreign key is useful in linking together two tables. Data should be entered in the foreign key column with great\n",
    "care, as wrongly entered data can invalidate the relationship between the two tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Difference between Vertical and Horizontal Scaling.\n",
    "\n",
    "Horizontal scaling means that you scale by adding more machines into your pool of resources whereas Vertical scaling \n",
    "means that you scale by adding more power (CPU, RAM) to an existing machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sharding\n",
    "\n",
    "Sharding is the process of storing data records across multiple machines and is MongoDB’s approach to meeting the \n",
    "demands of data growth. As the size of the data increases, a single machine may not be sufficient to store the data \n",
    "nor provide an acceptable read and write throughput. Sharding solves the problem with horizontal scaling. With \n",
    "sharding, you add more machines to support data growth and the demands of read and write operations.\n",
    "\n",
    "\n",
    "Partitioning is a general term used to describe the act of breaking up your logical data elements into multiple \n",
    "entities for the purpose of performance, availability, or maintainability. \n",
    "\n",
    "﻿Sharding is the equivalent of \"horizontal partitioning\".  When you shard a database, you create replica of the \n",
    "schema, and then divide what data is stored in each shard based on a shard key.  For example, I might shard my \n",
    "customer database using CustomerId as a shard key - I'd store ranges 0-10000 in one shard and 10001-20000 in a different shard.  When choosing a shard key, the DBA will typically look at data-access patterns and space issues to ensure that they are distributing load and space across shards evenly. \n",
    "\n",
    "﻿\"Vertical partitioning\" is the act of splitting up the data stored in one entity into multiple entities - again for \n",
    "space and performance reasons.  For example, a customer might only have one billing address, yet I might choose to \n",
    "put the billing address information into a separate table with a CustomerId reference so that I have the flexibility \n",
    "to move that information into a separate database, or different security context, etc.   \n",
    "\n",
    "To summarize - partitioning is a generic term that just means dividing your logical entities into different physical \n",
    "entities for performance, availability, or some other purpose.  \"Horizontal partitioning\", or sharding, is \n",
    "replicating the schema, and then dividing the data based on a shard key.  \"Vertical partitioning\" involves dividing \n",
    "up the schema (and the data goes along for the ride). \n",
    "\n",
    "Final note: ﻿ you can combine both horizontal and vertical partitioning techniques - sometimes required in big data, \n",
    "high traffic environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DML, DCL, DDL, TCL and their commands.\n",
    "\n",
    "What are the differences between DDL, DML and DCL in SQL?\n",
    "Ans: Following are some details of three.\n",
    "\n",
    "    \n",
    "DDL stands for Data Definition Language. SQL queries like CREATE, ALTER, DROP and RENAME come under this.\n",
    "CREATE – Creates objects in the database\n",
    "ALTER – Alters objects of the database\n",
    "DROP – Deletes objects of the database\n",
    "TRUNCATE – Deletes all records from a table and resets table identity to initial value.\n",
    "\n",
    "\n",
    "DML stands for Data Manipulation Language. SQL queries like SELECT, INSERT and UPDATE come under this.\n",
    "SELECT – Retrieves data from a table\n",
    "INSERT -  Inserts data into a table\n",
    "UPDATE – Updates existing data into a table\n",
    "DELETE – Deletes all records from a table\n",
    "\n",
    "\n",
    "DCL stands for Data Control Language. SQL queries like GRANT and REVOKE come under this.\n",
    "GRANT – Gives user's access privileges to database\n",
    "REVOKE – Withdraws user's access privileges to database given with the GRANT command\n",
    "\n",
    "TCL\n",
    "TCL is abbreviation of Transactional Control Language. It is used to manage different transactions occurring within a \n",
    "database.\n",
    "\n",
    "COMMIT – Saves work done in transactions\n",
    "ROLLBACK – Restores database to original state since the last COMMIT command in transactions\n",
    "SAVE TRANSACTION – Sets a savepoint within a transaction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Indexing in DBMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "What is normalization and de-normalization and why do we need it?\n",
    "\n",
    "While normalized data is optimized for entity level transactions, denormalized data is optimized for answering \n",
    "business questions and driving decision making. Denormalized data is data that has been extracted from the large \n",
    "collection of normalized tables and has been organized and/or aggregated into fewer tables without regard to such \n",
    "things as redundancy. Unlike the process of normalization, denormalization has fewer hard and fast rules about \n",
    "structure. There are schematic patterns, like snowflake, but the design is usually more specific to a particular \n",
    "organization’s needs. Reporting and decision support is simplified through a minimum of aggregated tables versus \n",
    "extracting data real time through multiple-table joins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal Forms  https://www.w3schools.in/dbms/database-normalization/\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Conflict Serializability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Can Primary key contain two entities?\n",
    "\n",
    "(Ans: No, there is one and only one primary key in any relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Concurrency Control  http://www.agiledata.org/essays/concurrencyControl.html\n",
    "\n",
    "A collision is said to occur when two activities, which may or may not be full-fledged transactions, attempt to \n",
    "change entities within a system of record. There are three fundamental ways (Celko 1999) that two activities can \n",
    "interfere with one another:\n",
    "Dirty read. Activity 1 (A1) reads an entity from the system of record and then updates the system of record but \n",
    "does not commit the change (for example, the change hasn’t been finalized). Activity 2 (A2) reads the entity, \n",
    "unknowingly making a copy of the uncommitted version. A1 rolls back (aborts) the changes, restoring the entity to the \n",
    "original state that A1 found it in. A2 now has a version of the entity that was never committed and therefore is not \n",
    "considered to have actually existed.\n",
    "\n",
    "Non-repeatable read. A1 reads an entity from the system of record, making a copy of it. A2 deletes the entity from \n",
    "the system of record. A1 now has a copy of an entity that does not officially exist.\n",
    "\n",
    "Phantom read. A1 retrieves a collection of entities from the system of record, making copies of them, based on some \n",
    "sort of search criteria such as “all customers with first name Bill.”A2 then creates new entities, which would have \n",
    "met the search criteria (for example, inserts “Bill Klassen” into the database), saving them to the system of record.\n",
    "If A1 reapplies the search criteria it gets a different result set.\n",
    "\n",
    "Collisions will occur the more that data is allowed to go stale in a cache and the more concurrent users/threads you\n",
    "have.\n",
    "\n",
    " \n",
    "\n",
    "2. Locking Strategies\n",
    "So what can you do? First, you can take a pessimistic locking approach that avoids collisions but reduces system \n",
    "performance.  Second, you can use an optimistic locking strategy that enables you to detect collisions so you can \n",
    "resolve them. Third, you can take an overly optimistic locking strategy that ignores the issue completely.\n",
    "\n",
    "2.1 Pessimistic Locking\n",
    "Pessimistic locking is an approach where an entity is locked in the database for the entire time that it is in \n",
    "application memory (often in the form of an object). A lock either limits or prevents other users from working with \n",
    "the entity in the database. A write lock indicates that the holder of the lock intends to update the entity and \n",
    "disallows anyone from reading, updating, or deleting the entity.  A read lock indicates that the holder of the lock \n",
    "does not want the entity to change while the hold the lock, allowing others to read the entity but not update or \n",
    "delete it. The scope of a lock might be the entire database, a table, a collection of rows, or a single row. These \n",
    "types of locks are called database locks, table locks, page locks, and row locks respectively.  \n",
    "The advantages of pessimistic locking are that it is easy to implement and guarantees that your changes to the \n",
    "database are made consistently and safely. The primary disadvantage is that this approach isn’t scalable.  When a \n",
    "system has many users, or when the transactions involve a greater number of entities, or when transactions are long \n",
    "lived, then the chance of having to wait for a lock to be released increases.  Therefore this limits the practical \n",
    "number of simultaneous users that your system can support.\n",
    "Agile Database Techniques\n",
    "\n",
    "2.2 Optimistic Locking\n",
    "With multi-user systems it is quite common to be in a situation where collisions are infrequent. Although the two of \n",
    "us are working with Customer objects, you’re working with the Wayne Miller object while I work with the John Berg \n",
    "object and therefore we won’t collide. When this is the case optimistic locking becomes a viable concurrency control \n",
    "strategy.  The idea is that you accept the fact that collisions occur infrequently, and instead of trying to prevent \n",
    "them you simply choose to detect them and then resolve the collision when it does occur.\n",
    "Figure 1 depicts the logic for updating an object when optimistic locking is used.  The application reads the object \n",
    "into memory.  To do this a read lock is obtained on the data, the data is read into memory, and the lock is released. \n",
    "At this point in time the row(s) may be marked to facilitate detection of a collision (more on this later). \n",
    "The application then manipulates the object until the point that it needs to be updated. The application then obtains \n",
    "a write lock on the data and reads the original source back so as to determine if there’s been a collision. \n",
    "The application determines that there has not been a collision so it updates the data and unlocks it. Had a collision \n",
    "been detected, e.g. the data had been updated by another process after it had originally been read into memory, then \n",
    "the collision would need to be resolved.\n",
    "\n",
    "There are two basic strategies for determining if a collision has occurred:\n",
    "Mark the source with a unique identifier.  The source data row is marked with a unique value each time it is updated. At the point of update, the mark is checked, and if there is a different value than what you originally read in, then you know that there has been an update to the source. There are different types of concurrency marks:\n",
    "Datetime stamps (the database server should assign this value because you can’t count on the time clocks of all machines to be in sync).\n",
    "Incremental counters.\n",
    "User IDs (this only works if everyone has a unique ID and you’re logged into only one machine and the applications ensure that only one copy of an object exists in memory).\n",
    "Values generated by a globally unique surrogate key generator.\n",
    "Retain a copy of the original.  The source data is retrieved at the point of updating and compared with the values that were originally retrieved. If the values have changed, then a collision has occurred. This strategy may be your only option if you are unable to add sufficient columns to your database schema to maintain the concurrency marks.\n",
    "Figure 1 depicts a naïve approach, and in fact there are ways to reduce the number of database interactions.  The first three requests to the database – the initial lock, marking (if appropriate) the source data, and unlocking – can be performed as a single transaction. The next two interactions, to lock and obtain a copy of the source data, can easily be combined as a single trip to the database.  Furthermore the update and unlock can similarly be combined.  Another way to improve this is to combine the last four interactions into a single transaction and simply perform collision detection on the database server instead of the application server.\n",
    "\n",
    "2.3 Overly Optimistic Locking\n",
    "With the strategy you neither try to avoid nor detect collisions, assuming that they will never occur. This strategy \n",
    "is appropriate for single user systems, systems where the system of record is guaranteed to be accessed by only one \n",
    "user or system process at a time, or read-only tables. These situations do occur. It is important to recognize that \n",
    "this strategy is completely inappropriate for multi-user systems. \n",
    "\n",
    " \n",
    "3. Collision Resolution Strategies\n",
    "You have five basic strategies that you can apply to resolve collisions:\n",
    "Give up. \n",
    "Display the problem and let the user decide.   \n",
    "Merge the changes. \n",
    "Log the problem so someone can decide later. \n",
    "Ignore the collision and overwrite. \n",
    "It is important to recognize that the granularity of a collision counts. Assume that both of us are working with a \n",
    "copy of the same Customer entity. If you update a customer’s name and I update their shopping preferences, then we \n",
    "can still recover from this collision. In effect the collision occurred at the entity level, we updated the same \n",
    "customer, but not at the attribute level. It is very common to detect potential collisions at the entity level then \n",
    "get smart about resolving them at the attribute level.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Insertion in B trees\n",
    "\n",
    "The B-tree insertion algorithm is just the opposite: it adds new nodes at the top of the tree (a new node is\n",
    "allocated only when the root splits). B-trees grow at the root, not at the leaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "It should be noted that a relational database is not exactly the same thing as a relational database management \n",
    "system (RDBMS). The latter is a program that allows you to create, update, and administer a relational database.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "What is E-R model?\n",
    "This data model is based on the real world that consists of basic objects called entities and of a relationship among \n",
    "these objects.\n",
    "Entities are described in a database by a set of attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Describe the three levels of data abstraction?\n",
    "Physical Level - This is the lowest level of data abstraction which describes how the data is to be stored in the \n",
    "database.\n",
    "\n",
    "Logical level - The level describes the data in the database as well as relations between these database.\n",
    "\n",
    "View Level- This is the highest level of data abstraction , only some part of actual database is viewed by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Define the \"integrity rules\"\n",
    "There are two Integrity rules.\n",
    "> Entity Integrity: States that â€œPrimary key cannot have NULL valueâ€\n",
    "> Referential Integrity: States that â€œForeign Key can be either a NULL value or should be Primary Key value of \n",
    "    other relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "What is Weak Entity set?\n",
    "An entity set may not have sufficient attributes to form a primary key, and its primary key comprises of its partial\n",
    "key and the primary key of its parent entity, then it is said to be Weak Entity set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "There is a table where only one row is fully repeated. Write a Query to find the Repeated row\n",
    "Name\tSection\n",
    "abc\tCS1\n",
    "bcd\tCS2\n",
    "abc\tCS1\n",
    "\n",
    "In the above table, we can find duplicate row using below query.\n",
    "\n",
    "SELECT name, section FROM tbl\n",
    "GROUP BY name, section\n",
    "HAVING COUNT(*) > 1\n",
    "----------------------------------------------------------------------------------------------------------------------\n",
    "Query to find 2nd highest salary of an employee?\n",
    "\n",
    "SELECT max(salary) FROM EMPLOYEES WHERE salary IN\n",
    "(SELECT salary FROM EMPLOYEEs MINUS SELECT max(salary)\n",
    "FROM EMPLOYEES);\n",
    "\n",
    "\n",
    "or\n",
    "\n",
    "SELECT max(salary) FROM EMPLOYEES WHERE \n",
    "salary <> (SELECT max(salary) FROM EMPLOYEES);\n",
    "\n",
    "----------------------------------------------------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q.Consider the following Employee table. How many rows are there in the result of following query?\n",
    "\n",
    "ID   salary   DeptName\n",
    "1    10000      EC\n",
    "2    40000      EC\n",
    "3    30000      CS\n",
    "4    40000      ME\n",
    "5    50000      ME\n",
    "6    60000      ME\n",
    "7    70000      CS\n",
    "\n",
    "How many rows are there in the result of following query?\n",
    "\n",
    "SELECT E.ID\n",
    "FROM  Employee E\n",
    "WHERE  EXISTS  (SELECT E2.salary\n",
    "FROM Employee E2\n",
    "WHERE E2.DeptName = 'CS'\n",
    "AND   E.salary > E2.salary)\n",
    "\n",
    "Following 5 rows will be result of query as 3000 is the minimum salary of CS Employees and all these rows are greater than 30000.\n",
    "\n",
    "2\n",
    "4\n",
    "5\n",
    "6\n",
    "7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q. Difference between primary key and unique key and why one should use unique key if it allows only one null ?\n",
    "\n",
    "Primary key:\n",
    "Only one in a row(tuple).\n",
    "Never allows null value(only key field).\n",
    "Unique key identifier and can not be null and must be unique.\n",
    "----------------------------------------------------------------------------------------------------------------------\n",
    "Unique Key:\n",
    "Can be more than one unique key in one row.\n",
    "Unique key can have null values(only single null is allowed).\n",
    "It can be a candidate key.\n",
    "Unique key can be null and may not be unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "What’s the difference between materialized and dynamic view?\n",
    "\n",
    "Materialized views\n",
    "\n",
    "Disk based and are updated periodically based upon the query definition.\n",
    "A materialized table is created or updated infrequently and it must be synchronized with its associated base tables.\n",
    "----------------------------------------------------------------------------------------------------------------------\n",
    "Dynamic views\n",
    "\n",
    "Virtual only and run the query definition each time they are accessed.\n",
    "A dynamic view may be created every time that a specific view is requested by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "What is embedded and dynamic SQL? https://www.geeksforgeeks.org/commonly-asked-dbms-interview-questions-set-2/\n",
    "\n",
    "Static or Embedded SQL\n",
    "\n",
    "SQL statements in an application that do not change at runtime and, therefore, can be hard-coded into the application.\n",
    "----------------------------------------------------------------------------------------------------------------------\n",
    "Dynamic SQL\n",
    "\n",
    "SQL statements that are constructed at runtime; for example, the application may allow users to enter their own \n",
    "queries.\n",
    "\n",
    "Dynamic SQL is a programming technique that enables you to buildSQL statements dynamically at runtime. \n",
    "You can create more general purpose, flexible applications by using dynamic SQL because the full text of a SQL \n",
    "statement may be unknown at compilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "What is the difference between CHAR and VARCHAR?\n",
    "\n",
    "CHAR and VARCHAR are differ in storage and retrieval.\n",
    "CHAR column length is fixed while VARCHAR length is variable.\n",
    "The maximum no. of character CHAR data type can hold is 255 character while VARCHAR can hold up to 4000 character.\n",
    "CHAR is 50% faster than VARCHAR.\n",
    "CHAR uses static memory allocation while VARCHAR uses dynamic memory allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Select all names that start with a given letter.\n",
    "\n",
    "Select *\n",
    "From employees \n",
    "Where Fname like 'A%';\n",
    "\n",
    "Select *\n",
    "From employees \n",
    "Where left(FName, 1)='A';\n",
    "\n",
    "Select *\n",
    "From employees \n",
    "Where substring(FName, 1, 1)='A'; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "What are indexes?\n",
    "\n",
    "Ans: A database index is a data structure that improves the speed of data retrieval operations on a database table at \n",
    "the cost of additional writes and the use of more storage space to maintain the extra copy of data.\n",
    "Data can be stored only in one order on disk. To support faster access according to different values, faster search \n",
    "like binary search for different values is desired, For this purpose, indexes are created on tables. These indexes need extra space on disk, but they allow faster search according to different frequently searched values.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
